# 完善AI健康助手大模型调用方案

## 问题分析

当前AI健康助手的大模型调用存在以下问题：

1. **模型调用逻辑单一**：仅调用edge模型，没有实现讯飞星火大模型的REST API和WebSocket API调用
2. **参数配置未充分利用**：force和preferStreaming参数设置了但未实际使用
3. **缺乏降级机制**：当一个模型调用失败时，没有尝试其他可用模型
4. **错误处理不完善**：直接抛出异常，没有优雅的错误处理机制

## 解决方案

完善`AIChatRepository.kt`中的`sendMessage`函数，实现以下功能：

### 1. 多模型调用逻辑

根据参数和配置选择合适的模型调用：
- 当`force=true`时，优先使用指定模型
- 当`preferStreaming=true`时，优先使用WebSocket流式调用
- 实现edge模型、讯飞星火REST API、讯飞星火WebSocket API的调用逻辑

### 2. 降级机制

实现模型调用的降级链：
- 优先尝试WebSocket流式调用
- 失败后尝试REST API调用
- 最后尝试edge模型调用
- 所有模型调用失败时返回fallback响应

### 3. 参数优化

- 充分利用用户配置的API密钥和参数
- 根据环境配置自动选择可用模型
- 实现模型参数的动态调整

### 4. 错误处理

- 完善异常捕获和处理
- 提供友好的错误提示
- 记录错误日志便于调试

## 实现步骤

1. 重构`sendMessage`函数，实现多模型调用逻辑
2. 添加模型调用的降级机制
3. 完善参数配置和利用
4. 增强错误处理和日志记录
5. 测试不同模型的调用效果

## 预期效果

- AI助手能够根据配置和参数自动选择最优模型
- 提高模型调用的成功率和响应速度
- 实现优雅的降级机制，避免服务完全不可用
- 充分利用所有可用的AI模型资源

## 涉及文件

- `app/src/main/java/com/example/healthapp/data/repository/AIChatRepository.kt`